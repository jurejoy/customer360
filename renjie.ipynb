{"cells":[{"cell_type":"code","source":["# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path = \"tracks.csv\"\nclicks_blob_relative_path = \"clicks.csv\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n# Allow SPARK to read from Blob remotely\nwasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\nclicks_wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, clicks_blob_relative_path)\nspark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n\nfrom pyspark import SparkContext, SparkConf  \nfrom operator import add\nimport csv  \n\nsc = SparkContext.getOrCreate()\n\ntrackfile = sc.textFile(wasbs_path)\n\n\ndef make_tracks_kv(str):\n    l = str.split(\",\")\n    return [l[1], [[int(l[2]), l[3], int(l[4]), l[5]]]]\n\n# make a k,v RDD out of the input data  \ntbycust = trackfile.map(lambda line: make_tracks_kv(line)).reduceByKey(lambda a, b: a + b)\ntbycust.take(1)\n\n\ndef clicks_summary(str):\n    l = str.split(\",\")\n    custid = l[1]\n    adv = l[2]\n    if (adv == \"ADV_REDUCED_1DAY\"):\n        return (custid, 1)\n\ndef user_clicked(line, which):\n    eid, custid, adclicked, ltime = line.split(\",\")\n    if (which in adclicked):\n        return (custid, 1)\n    else:\n        return (custid, 0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["def compute_stats_byuser(tracks):\n    mcount = morn = aft = eve = night = 0\n    tracklist = []\n    for t in tracks:\n        trackid, dtime, mobile, zip = t\n        if trackid not in tracklist:\n            tracklist.append(trackid)\n        d, t = dtime.split(\" \")\n        hourofday = int(t.split(\":\")[0])\n        mcount += mobile\n        if (hourofday < 5):\n            night += 1\n        elif (hourofday < 12):\n            morn += 1\n        elif (hourofday < 17):\n            aft += 1\n        elif (hourofday < 22):\n            eve += 1\n        else:\n            night += 1\n    return [len(tracklist), morn, aft, eve, night, mcount]\n\n# compute profile for each user  \ncustdata = tbycust.mapValues(lambda a: compute_stats_byuser(a))  \ncustdata.take(1)\n#custdata.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: [(&#39;48&#39;, [696, 310, 217, 223, 277, 503])]</div>"]}}],"execution_count":2},{"cell_type":"code","source":["def compute_stats_byuser(tracks):\n    mcount = morn = aft = eve = night = 0\n    tracklist = []\n    for t in tracks:\n        trackid, dtime, mobile, zip = t\n        if trackid not in tracklist:\n            tracklist.append(trackid)\n        d, t = dtime.split(\" \")\n        hourofday = int(t.split(\":\")[0])\n        mcount += mobile\n        if (hourofday < 5):\n            night += 1\n        elif (hourofday < 12):\n            morn += 1\n        elif (hourofday < 17):\n            aft += 1\n        elif (hourofday < 22):\n            eve += 1\n        else:\n            night += 1\n    return [len(tracklist), morn, aft, eve, night, mcount]\n\n# compute profile for each user  \ncustdata = tbycust.mapValues(lambda a: compute_stats_byuser(a))  \ncustdata.take(1)\n#custdata.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: [(&#39;1903&#39;, [169, 53, 34, 33, 58, 90])]</div>"]}}],"execution_count":3},{"cell_type":"code","source":[" \nfrom pyspark.mllib.stat import Statistics  \n  \n\n# compute aggregate stats for entire track history  \naggdata = Statistics.colStats(custdata.map(lambda x: x[1]))\nprint(aggdata.mean())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[170.295   58.2908  41.6434  41.7626  58.3032 121.553 ]\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["from os.path import expanduser, join, abspath\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Row\nfrom pyspark import SparkContext, SparkConf  \n\n# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path = \"tracks.csv\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n# Allow SPARK to read from Blob remotely\nwasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n\n\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Python Spark SQL Hive integration example\") \\\n    .config(\"spark.sql.warehouse.dir\", wasbs_path) \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\n# spark is an existing SparkSession\nspark.sql(\"TRUNCATE TABLE ltable\")\nspark.sql(\"CREATE TABLE IF NOT EXISTS ltable (unique INT, morn INT, aft INT, eve INT, night INT, mobile INT) USING hive\")\n#spark.sql(\"LOAD DATA LOCAL INPATH 'examples/src/main/resources/kv1.txt' INTO TABLE src\")\n\n# Queries are expressed in HiveQL\nspark.sql(\"SELECT * FROM ltable\").show()\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+----+---+---+-----+------+\nunique|morn|aft|eve|night|mobile|\n+------+----+---+---+-----+------+\n+------+----+---+---+-----+------+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["custdatalen = custdata.count()\nvalues = list()\nkeys = list()\nfor line in custdata.values().take(custdatalen):\n    values.append(line)\n\nfor line in custdata.keys().take(custdatalen):\n    keys.append(line)\n\n#print(str(keys[0]))\n\n\n\n#for i in range (0,(custdatalen-1)):\nfor i in range (0,1):\n    unique = int(keys[i])\n    morn = int(values[i][0])\n    aft = int(values[i][1])\n    eve = int(values[i][2])\n    night = int(values[i][3])\n    mobile = int(values[i][4])\n    print(morn)\n    #spark.sql(\"INSERT INTO TABLE ltable VALUES('${unique}','${morn}','${aft}','${eve}','${night}','${mobile}')\")\n    spark.sql(\"INSERT INTO TABLE ltable VALUES(%s,%s,%s,%s,%s,%s)\" % (unique,morn,aft,eve,night,mobile))\n\n\nspark.sql(\"SELECT count(*) FROM ltable\").show()\n#for i in range (0,9):\n#    print(values[i][0])\n\n#values = custdata.values().take(1)\n\n#value = value [0]\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">696\n+--------+\ncount(1)|\n+--------+\n       1|\n+--------+\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["clicksfile = sc.textFile(clicks_wasbs_path)\n# distill the clicks down to a smaller data set that is faster\nclickdata = clicksfile.map(lambda line:user_clicked(line, \"ADV_REDUCED_1DAY\")).reduceByKey(add)\nsortedclicks = clickdata.sortByKey()\nsortedclicks.values().take(10)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</div>"]}}],"execution_count":7},{"cell_type":"code","source":["\nfrom pyspark.sql import *\nltablelist = []\nltablelist.append((\"unique\", \"morn\", \"aft\", \"eve\",\"night\",\"mobile\"))\n\n\ncustdatalen = custdata.count()\nvalues = list()\nkeys = list()\nfor line in custdata.values().take(custdatalen):\n    values.append(line)\n\nfor line in custdata.keys().take(custdatalen):\n    keys.append(line)\n    \n    \n#ltablelist = []\nfor i in range (0,(custdatalen-1)):\n    ltablelist.append((str(keys[i]), str(values[i][0]), str(values[i][1]), str(values[i][2]), str(values[i][3]), str(values[i][4])))\n  \n\n#print(ltablelist)\nltabledf = sqlContext.createDataFrame(ltablelist)\n\n\n\n####creat train table############\n\nttablelist = []\nttablelist.append((\"clicked\",\"unique\", \"morn\", \"aft\", \"eve\",\"night\",\"mobile\"))\n\n#sortedclicks.take(10)\n#print(sortedclicks.lookup('1000')[0])\n\nsortedclickslen = sortedclicks.count\ncvalues = list()\nckeys = list()\nfor line in custdata.values().take(custdatalen):\n    cvalues.append(line)\n\nfor line in custdata.keys().take(custdatalen):\n    ckeys.append(line)\n\nfor i in range (0,(custdatalen-1)):\n    tot = cvalues[i][0] + cvalues[i][1] + cvalues[i][2] + cvalues[i][3]\n    if sortedclicks.lookup(str(ckeys[i]))[0] > 0:\n      clicked = 1\n    else:\n      clicked = 0\n    ttablelist.append((str(clicked), str(ckeys[i]), str(values[i][0]/tot), str(values[i][1]/tot), str(values[i][2]/tot), str(values[i][3]/tot), str(values[i][4]/tot)))\n    \n    \n\n#print(ttablelist)\nttabledf = sqlContext.createDataFrame(ttablelist)\nttabledf.take(10)\n\n\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: [Row(_1=&#39;clicked&#39;, _2=&#39;unique&#39;, _3=&#39;morn&#39;, _4=&#39;aft&#39;, _5=&#39;eve&#39;, _6=&#39;night&#39;, _7=&#39;mobile&#39;),\n Row(_1=&#39;0&#39;, _2=&#39;1903&#39;, _3=&#39;0.48132780082987553&#39;, _4=&#39;0.2143845089903181&#39;, _5=&#39;0.15006915629322268&#39;, _6=&#39;0.1542185338865837&#39;, _7=&#39;0.19156293222683266&#39;),\n Row(_1=&#39;1&#39;, _2=&#39;304&#39;, _3=&#39;0.5630252100840336&#39;, _4=&#39;0.17086834733893558&#39;, _5=&#39;0.1484593837535014&#39;, _6=&#39;0.11764705882352941&#39;, _7=&#39;0.20448179271708683&#39;),\n Row(_1=&#39;0&#39;, _2=&#39;3538&#39;, _3=&#39;0.5714285714285714&#39;, _4=&#39;0.15625&#39;, _5=&#39;0.16964285714285715&#39;, _6=&#39;0.10267857142857142&#39;, _7=&#39;0.17857142857142858&#39;),\n Row(_1=&#39;0&#39;, _2=&#39;4&#39;, _3=&#39;0.5440613026819924&#39;, _4=&#39;0.20306513409961685&#39;, _5=&#39;0.13026819923371646&#39;, _6=&#39;0.12260536398467432&#39;, _7=&#39;0.15708812260536398&#39;),\n Row(_1=&#39;0&#39;, _2=&#39;157&#39;, _3=&#39;0.5635593220338984&#39;, _4=&#39;0.13983050847457626&#39;, _5=&#39;0.1652542372881356&#39;, _6=&#39;0.13135593220338984&#39;, _7=&#39;0.17796610169491525&#39;),\n Row(_1=&#39;0&#39;, _2=&#39;112&#39;, _3=&#39;0.6018518518518519&#39;, _4=&#39;0.16666666666666666&#39;, _5=&#39;0.14351851851851852&#39;, _6=&#39;0.08796296296296297&#39;, _7=&#39;0.22685185185185186&#39;),\n Row(_1=&#39;0&#39;, _2=&#39;834&#39;, _3=&#39;0.5483870967741935&#39;, _4=&#39;0.17972350230414746&#39;, _5=&#39;0.14285714285714285&#39;, _6=&#39;0.12903225806451613&#39;, _7=&#39;0.15207373271889402&#39;),\n Row(_1=&#39;0&#39;, _2=&#39;4242&#39;, _3=&#39;0.564748201438849&#39;, _4=&#39;0.17985611510791366&#39;, _5=&#39;0.14388489208633093&#39;, _6=&#39;0.11151079136690648&#39;, _7=&#39;0.17985611510791366&#39;),\n Row(_1=&#39;0&#39;, _2=&#39;520&#39;, _3=&#39;0.5603015075376885&#39;, _4=&#39;0.17336683417085427&#39;, _5=&#39;0.12562814070351758&#39;, _6=&#39;0.1407035175879397&#39;, _7=&#39;0.20854271356783918&#39;)]</div>"]}}],"execution_count":8},{"cell_type":"code","source":["####creat train table############\n\ntrain = []\n\n#sortedclicks.take(10)\n#print(sortedclicks.lookup('1000')[0])\n\nsortedclickslen = sortedclicks.count\ncvalues = list()\nckeys = list()\nfor line in custdata.values().take(custdatalen):\n    cvalues.append(line)\n\nfor line in custdata.keys().take(custdatalen):\n    ckeys.append(line)\n\nfor i in range (0,(custdatalen-1)):\n    tot = cvalues[i][0] + cvalues[i][1] + cvalues[i][2] + cvalues[i][3]\n    if sortedclicks.lookup(str(ckeys[i]))[0] > 0:\n      clicked = 1\n    else:\n      clicked = 0\n    train.append((str(clicked), \"1:\"+str(values[i][0]/tot), \"2:\"+str(values[i][1]/tot), \"3:\"+str(values[i][2]/tot), \"4:\"+str(values[i][3]/tot), \"5:\"+str(values[i][4]/tot)))\n    \n    \n\n#print(ttablelist)\ntraindf = sqlContext.createDataFrame(train)\ntraindf.take(10)\n\n\n\n###############################make txt####################################\n\n# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path = \"tracks.csv\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n# Allow SPARK to read from Blob remotely\nwasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\nspark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path = \"ltable.csv\"\nblob_relative_path_train = \"ttable.csv\"\nblob_relative_path_traintxt = \"train.txt\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n# Allow SPARK to read from Blob remotely\nwasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\nwasbs_path_train = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_train)\nwasbs_path_traintxt = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_traintxt)\nspark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n\n\n\ntraindf.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"false\").option(\"delimiter\", \" \").mode(\"overwrite\").save(wasbs_path_traintxt)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path = \"tracks.csv\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n# Allow SPARK to read from Blob remotely\nwasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\nspark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path = \"ltable.csv\"\nblob_relative_path_train = \"ttable.csv\"\nblob_relative_path_traintxt = \"ttable.txt\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n# Allow SPARK to read from Blob remotely\nwasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\nwasbs_path_train = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_train)\nwasbs_path_traintxt = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_traintxt)\nspark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n\n\n\nfrom pyspark import SparkContext, SparkConf  \nimport csv  \n\n\nltabledf.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"false\").mode(\"overwrite\").save(wasbs_path)\nttabledf.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"false\").mode(\"overwrite\").save(wasbs_path_train)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path_ml = \"features.csv\"\nblob_relative_path_mloutput = \"pridictions.csv\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n\n# Allow SPARK to read from Blob remotely\nwasbs_path_ml = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_ml)\nwasbs_path_mloutput = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_mloutput)\nspark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n\n\n\nsc = SparkContext.getOrCreate()\n\ndata = spark.read.csv(wasbs_path_ml, header=True, inferSchema=True)\n\n\n# split the data into training, and test \ntrain, test = data.randomSplit([0.7, 0.3], seed = 0)\ntrain.describe().show()\n\n\nfrom pyspark.ml.feature import RFormula\nformula = RFormula(formula=\"clicked ~ morn + aft + eve + night + mobile\",\n                   featuresCol=\"features\",labelCol=\"label\")\n\ntrain_cv = formula.fit(train).transform(train)\ntest_cv = formula.fit(test).transform(test)\n\n\nfrom pyspark.ml.regression import RandomForestRegressor\nrf = RandomForestRegressor()\n\nmodel1 = rf.fit(train_cv)\npredictions = model1.transform(test_cv)\npredictions.show(50)\n\n\nfrom pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator()\nmse = evaluator.evaluate(predictions,{evaluator.metricName:\"mse\" })\nimport numpy as np\nnp.sqrt(mse), mse\n\npredictionsdf = predictions.selectExpr(\"clicked as clicked\", \"prediction as prediction\")\npredictionsdf.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"false\").mode(\"overwrite\").save(wasbs_path_mloutput)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\nsummary|            clicked|            unique|                morn|                 aft|                 eve|               night|             mobile|\n+-------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n  count|               3527|              3527|                3527|                3527|                3527|                3527|               3527|\n   mean| 0.1482846611851432| 2499.853132974199|  0.5614178121539556| 0.18040294761610418|  0.1290118063850293| 0.12916743384519444|  0.181504211017862|\n stddev|0.35543232692657345|1449.5817484992754|0.022787987596370785|0.022795279609973376|0.020289793926964148|0.020238589994246454|0.02787629644112722|\n    min|                  0|                 1|          0.29555686|         0.107784431|         0.065217391|         0.052631579|            0.09375|\n    max|                  1|              4998|         0.634730539|         0.301037385|         0.215568862|         0.208860759|        0.288901938|\n+-------+-------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n\n+-------+------+-----------+-----------+-----------+-----------+-----------+--------------------+-----+--------------------+\nclicked|unique|       morn|        aft|        eve|      night|     mobile|            features|label|          prediction|\n+-------+------+-----------+-----------+-----------+-----------+-----------+--------------------+-----+--------------------+\n      0|     0|0.246343693|0.305758684| 0.22242535|0.225472273|0.325868373|[0.246343693,0.30...|  0.0| 0.14287389181918858|\n      0|     3|0.580645161|0.182795699|0.123655914|0.112903226|0.215053763|[0.580645161,0.18...|  0.0|  0.1511154584113686|\n      0|     4|0.362878577|0.265351487|0.183662128|0.188107808|0.268963601|[0.362878577,0.26...|  0.0| 0.14287389181918858|\n      0|     5|0.582417582|0.197802198|0.120879121|0.098901099|0.181318681|[0.582417582,0.19...|  0.0|  0.1663497193978158|\n      0|     7|     0.5472|      0.184|     0.1424|     0.1264|     0.1936|[0.5472,0.184,0.1...|  0.0| 0.09575927433827976|\n      0|    18|0.586419753|0.169753086|0.111111111|0.132716049|0.203703704|[0.586419753,0.16...|  0.0| 0.18362208716717612|\n      0|    22| 0.46879835|0.216606498|0.162970603|0.151624549|0.232594121|[0.46879835,0.216...|  0.0| 0.07820055359886635|\n      0|    23|0.540584416|0.201298701|0.113636364|0.144480519|0.183441558|[0.540584416,0.20...|  0.0| 0.10035510668264813|\n      0|    26| 0.47107438| 0.21046832|0.169146006|0.149311295|0.225344353|[0.47107438,0.210...|  0.0| 0.07820055359886635|\n      0|    27|0.570934256|0.186851211|0.114186851|0.128027682|0.211072664|[0.570934256,0.18...|  0.0| 0.11629766943873265|\n      0|    31| 0.54296875|     0.1875| 0.12109375|  0.1484375| 0.16015625|[0.54296875,0.187...|  0.0| 0.11739135637018025|\n      0|    38|0.569086651|0.168618267|0.133489461|0.128805621|0.220140515|[0.569086651,0.16...|  0.0| 0.13436776296847328|\n      0|    40|0.479333333|      0.208|      0.162|0.150666667|0.193333333|[0.479333333,0.20...|  0.0| 0.07246346932977123|\n      0|    41| 0.55890411|0.180821918|0.115068493|0.145205479|0.175342466|[0.55890411,0.180...|  0.0|  0.1302306866239279|\n      0|    46|0.543859649|0.157894737|0.140350877|0.157894737| 0.14619883|[0.543859649,0.15...|  0.0| 0.15716018957658356|\n      0|    47| 0.54519774|0.161016949|0.141242938|0.152542373|0.177966102|[0.54519774,0.161...|  0.0| 0.11666858239274078|\n      0|    52| 0.52540107|0.184491979|0.143048128|0.147058824|0.171122995|[0.52540107,0.184...|  0.0| 0.09318661581476595|\n      0|    54|0.495607613|0.224011713|0.133235725|0.147144949|0.199853587|[0.495607613,0.22...|  0.0|  0.0649574218882565|\n      0|    58|0.507857734|0.201819686|0.142266336|0.148056245|0.208436725|[0.507857734,0.20...|  0.0|  0.0603257089985748|\n      0|    61|0.559006211|0.186335404|0.124223602|0.130434783|0.173913043|[0.559006211,0.18...|  0.0|  0.1279812148130181|\n      0|    64|0.494318182|0.209415584|0.146103896|0.150162338|0.199675325|[0.494318182,0.20...|  0.0| 0.04944843171880936|\n      0|    65|0.545864662|0.183458647|0.136842105|0.133834586|0.196992481|[0.545864662,0.18...|  0.0| 0.09985830181067618|\n      0|    67| 0.53262519| 0.17754173|0.142640364|0.147192716|0.169954476|[0.53262519,0.177...|  0.0| 0.10028980211335455|\n      0|    68|0.512319456|0.187765506|0.147833475|0.152081563|0.235344095|[0.512319456,0.18...|  0.0| 0.07229698557388844|\n      0|    72|0.551282051|0.168803419|0.113247863|0.166666667|0.179487179|[0.551282051,0.16...|  0.0| 0.15061558630003574|\n      0|    80|0.560693642|0.190751445|0.121387283| 0.12716763|0.144508671|[0.560693642,0.19...|  0.0| 0.13778450850227492|\n      0|    84|0.509107468|0.194899818|0.141165756|0.154826958|0.203096539|[0.509107468,0.19...|  0.0| 0.07267599161051728|\n      0|    85|   0.553125|   0.184375|    0.13125|    0.13125|   0.153125|[0.553125,0.18437...|  0.0| 0.13110438981646372|\n      0|    92|0.574712644|0.172413793|0.130268199|0.122605364|0.195402299|[0.574712644,0.17...|  0.0| 0.14929026445837176|\n      0|    93|0.511025887|0.201342282|0.132310642|0.155321189|0.212847555|[0.511025887,0.20...|  0.0| 0.06894943527446509|\n      0|    99|0.565957447|        0.2|0.110638298|0.123404255|0.182978723|[0.565957447,0.2,...|  0.0| 0.11953946096516792|\n      0|   103|0.543706294|0.192307692|0.134615385|0.129370629|0.190559441|[0.543706294,0.19...|  0.0| 0.08631596264815815|\n      0|   105|0.574712644| 0.16091954|0.143678161|0.120689655|0.201149425|[0.574712644,0.16...|  0.0| 0.18751545065852632|\n      0|   106|0.507604563|0.185361217|0.152091255|0.154942966|0.191064639|[0.507604563,0.18...|  0.0| 0.06529674925917116|\n      0|   110|0.509625127|  0.2147923| 0.14893617|0.126646403|0.216818642|[0.509625127,0.21...|  0.0| 0.05905362287367917|\n      0|   113|0.505494505|0.197802198| 0.14985015|0.146853147|0.188811189|[0.505494505,0.19...|  0.0| 0.06879339728765956|\n      0|   119|0.516666667|0.205208333|     0.1375|   0.140625|0.192708333|[0.516666667,0.20...|  0.0| 0.06304016911137081|\n      0|   121|0.507874016|0.215551181|0.133858268|0.142716535|0.191929134|[0.507874016,0.21...|  0.0| 0.06942520900310244|\n      0|   124|0.556074766|0.196261682|0.140186916|0.107476636|0.135514019|[0.556074766,0.19...|  0.0| 0.19258762867300694|\n      0|   127|0.568720379|0.156398104|0.132701422|0.142180095|0.170616114|[0.568720379,0.15...|  0.0| 0.16906891335847032|\n      0|   129|0.542234332|0.158038147|0.125340599|0.174386921|0.141689373|[0.542234332,0.15...|  0.0| 0.18875192951214614|\n      0|   136|0.550955414|0.194267516|0.121019108|0.133757962|0.178343949|[0.550955414,0.19...|  0.0| 0.10845032888787139|\n      0|   138|0.507919747|0.202745512| 0.13938754|0.149947202| 0.18373812|[0.507919747,0.20...|  0.0| 0.07696889389981407|\n      0|   139|0.523127753|0.183920705|0.146475771|0.146475771|0.204845815|[0.523127753,0.18...|  0.0| 0.06207896214432522|\n      0|   143|0.522700815|0.194412107|0.161816065|0.121071013|0.196740396|[0.522700815,0.19...|  0.0| 0.06213179113150582|\n      0|   147|0.516646116|0.200986436|0.145499383|0.136868064|0.202219482|[0.516646116,0.20...|  0.0| 0.05142505930039972|\n      0|   153|0.536523929|0.205289673| 0.14231738|0.115869018|0.206549118|[0.536523929,0.20...|  0.0| 0.06986376737494118|\n      0|   158|0.510613208|0.189858491|0.153301887|0.146226415|0.194575472|[0.510613208,0.18...|  0.0|0.056878312640298204|\n      0|   160| 0.52853598| 0.17866005|0.135235732|0.157568238|0.212158809|[0.52853598,0.178...|  0.0| 0.13478455802366776|\n      0|   166|0.597156398| 0.17535545|0.118483412|0.109004739|0.222748815|[0.597156398,0.17...|  0.0| 0.22553869050022718|\n+-------+------+-----------+-----------+-----------+-----------+-----------+--------------------+-----+--------------------+\nonly showing top 50 rows\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path_ml = \"train1.txt\"\nblob_relative_path_mloutput = \"pridictions.csv\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n\n# Allow SPARK to read from Blob remotely\nwasbs_path_ml = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_ml)\nwasbs_path_mloutput = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_mloutput)\nspark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n\n\n\nsc = SparkContext.getOrCreate()\n\n\n\n\n\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# Load and parse the data file, converting it to a DataFrame.\n#data = spark.read.csv(wasbs_path_ml, header=True, inferSchema=True)\ndata = spark.read.format(\"libsvm\").load(wasbs_path_ml)\n\n\n# Index labels, adding metadata to the label column.\n# Fit on whole dataset to include all labels in index.\nlabelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n# Automatically identify categorical features, and index them.\n# Set maxCategories so features with > 4 distinct values are treated as continuous.\nfeatureIndexer =\\\n    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n\n# Split the data into training and test sets (30% held out for testing)\n(trainingData, testData) = data.randomSplit([0.7, 0.3])\n\n# Train a GBT model.\ngbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n\n# Chain indexers and GBT in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n\n# Train model.  This also runs the indexers.\nmodel = pipeline.fit(trainingData)\n\n# Make predictions.\npredictions = model.transform(testData)\n\n# Select example rows to display.\npredictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\n\ngbtModel = model.stages[2]\nprint(gbtModel)  # summary only"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+------------+--------------------+\nprediction|indexedLabel|            features|\n+----------+------------+--------------------+\n       0.0|         0.0|(5,[0,1,2,3,4],[0...|\n       0.0|         0.0|(5,[0,1,2,3,4],[0...|\n       0.0|         0.0|(5,[0,1,2,3,4],[0...|\n       0.0|         0.0|(5,[0,1,2,3,4],[0...|\n       0.0|         0.0|(5,[0,1,2,3,4],[0...|\n+----------+------------+--------------------+\nonly showing top 5 rows\n\nTest Error = 0.153691\nGBTClassificationModel (uid=GBTClassifier_fe899ca545dd) with 10 trees\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# Azure storage access info\nblob_account_name = \"renjiedl\"\nblob_container_name = \"mapr\"\nblob_relative_path_ml = \"train1.txt\"\nblob_relative_path_mloutput = \"pridictions.csv\"\nblob_sas_token = \"https://renjiedl.blob.core.windows.net/?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-29T20:47:29Z&st=2020-03-19T12:47:29Z&spr=https&sig=36HtkrLxeQ952ynsD6b6aGIgWms7hduEyAaBSJagsGY%3D\"\n\n\n# Allow SPARK to read from Blob remotely\nwasbs_path_ml = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_ml)\nwasbs_path_mloutput = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path_mloutput)\nspark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n\n\n\nsc = SparkContext.getOrCreate()\n\n\n\n\n\n\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# Load training data\ndata = spark.read.format(\"libsvm\").load(wasbs_path_ml)\n\n# Split the data into train and test\nsplits = data.randomSplit([0.6, 0.4], 1234)\ntrain = splits[0]\ntest = splits[1]\n\n# create the trainer and set its parameters\nnb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n\n# train the model\nmodel = nb.fit(train)\n\n# select example rows to display.\npredictions = model.transform(test)\npredictions.show()\n\n# compute accuracy on the test set\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n                                              metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test set accuracy = \" + str(accuracy))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+----------+\nlabel|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+----------+\n  0.0|(5,[0,1,2,3,4],[0...|[-0.2571456379828...|[0.85316815601736...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.2670487504331...|[0.85316433999288...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.2772566672455...|[0.85316578272036...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.3145260047114...|[0.85316834623061...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.3238787742067...|[0.85316896180597...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.3333822945179...|[0.85316596293462...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.3541772148919...|[0.85316203556554...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.3998644801196...|[0.85316695995597...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4012966893986...|[0.85316832450484...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4080066372172...|[0.85317271990058...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4523091145258...|[0.85316142819558...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4268772420612...|[0.85316152015539...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4144934884389...|[0.85317130896656...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4368746813606...|[0.85316577960137...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4304765029982...|[0.85316963801594...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4448843406944...|[0.85316340579961...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4458334594449...|[0.85316448746978...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4384354653631...|[0.85317118286668...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4715466403522...|[0.85316116175290...|       0.0|\n  0.0|(5,[0,1,2,3,4],[0...|[-0.4716508873117...|[0.85317187711230...|       0.0|\n+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\nTest set accuracy = 0.8487903225806451\n</div>"]}}],"execution_count":13}],"metadata":{"name":"renjie","notebookId":3087353665161441},"nbformat":4,"nbformat_minor":0}
